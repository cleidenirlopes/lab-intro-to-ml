{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB | Intro to Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the data**\n",
    "\n",
    "In this challenge, we will be working with Spaceship Titanic data. The data can be found here:\n",
    "\n",
    "https://raw.githubusercontent.com/data-bootcamp-v4/data/main/spaceship_titanic.csv\n",
    "\n",
    "Metadata\n",
    "\n",
    "https://github.com/data-bootcamp-v4/data/blob/main/spaceship_titanic.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tabulate import tabulate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------------+--------------+-------------+---------+---------------+-------+-------+---------------+-------------+----------------+-------+----------+-------------------+---------------+\n",
      "|    |   PassengerId | HomePlanet   | CryoSleep   | Cabin   | Destination   |   Age | VIP   |   RoomService |   FoodCourt |   ShoppingMall |   Spa |   VRDeck | Name              | Transported   |\n",
      "+====+===============+==============+=============+=========+===============+=======+=======+===============+=============+================+=======+==========+===================+===============+\n",
      "|  0 |       0001_01 | Europa       | False       | B/0/P   | TRAPPIST-1e   |    39 | False |             0 |           0 |              0 |     0 |        0 | Maham Ofracculy   | False         |\n",
      "+----+---------------+--------------+-------------+---------+---------------+-------+-------+---------------+-------------+----------------+-------+----------+-------------------+---------------+\n",
      "|  1 |       0002_01 | Earth        | False       | F/0/S   | TRAPPIST-1e   |    24 | False |           109 |           9 |             25 |   549 |       44 | Juanna Vines      | True          |\n",
      "+----+---------------+--------------+-------------+---------+---------------+-------+-------+---------------+-------------+----------------+-------+----------+-------------------+---------------+\n",
      "|  2 |       0003_01 | Europa       | False       | A/0/S   | TRAPPIST-1e   |    58 | True  |            43 |        3576 |              0 |  6715 |       49 | Altark Susent     | False         |\n",
      "+----+---------------+--------------+-------------+---------+---------------+-------+-------+---------------+-------------+----------------+-------+----------+-------------------+---------------+\n",
      "|  3 |       0003_02 | Europa       | False       | A/0/S   | TRAPPIST-1e   |    33 | False |             0 |        1283 |            371 |  3329 |      193 | Solam Susent      | False         |\n",
      "+----+---------------+--------------+-------------+---------+---------------+-------+-------+---------------+-------------+----------------+-------+----------+-------------------+---------------+\n",
      "|  4 |       0004_01 | Earth        | False       | F/1/S   | TRAPPIST-1e   |    16 | False |           303 |          70 |            151 |   565 |        2 | Willy Santantines | True          |\n",
      "+----+---------------+--------------+-------------+---------+---------------+-------+-------+---------------+-------------+----------------+-------+----------+-------------------+---------------+\n"
     ]
    }
   ],
   "source": [
    "spaceship = pd.read_csv(\"D:\\Lab\\Week_16\\Titanic_Dataset.csv\")\n",
    "print(tabulate(spaceship.head(), headers='keys', tablefmt='grid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check the shape of your data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+\n",
      "|   Rows |   Columns |\n",
      "+========+===========+\n",
      "|   8693 |        14 |\n",
      "+--------+-----------+\n"
     ]
    }
   ],
   "source": [
    "# Check the shape of your data\n",
    "print(tabulate([spaceship.shape], headers=['Rows', 'Columns'], tablefmt='grid'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check for data types**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------+\n",
      "| Column       | Data Type   |\n",
      "+==============+=============+\n",
      "| PassengerId  | object      |\n",
      "+--------------+-------------+\n",
      "| HomePlanet   | object      |\n",
      "+--------------+-------------+\n",
      "| CryoSleep    | object      |\n",
      "+--------------+-------------+\n",
      "| Cabin        | object      |\n",
      "+--------------+-------------+\n",
      "| Destination  | object      |\n",
      "+--------------+-------------+\n",
      "| Age          | float64     |\n",
      "+--------------+-------------+\n",
      "| VIP          | object      |\n",
      "+--------------+-------------+\n",
      "| RoomService  | float64     |\n",
      "+--------------+-------------+\n",
      "| FoodCourt    | float64     |\n",
      "+--------------+-------------+\n",
      "| ShoppingMall | float64     |\n",
      "+--------------+-------------+\n",
      "| Spa          | float64     |\n",
      "+--------------+-------------+\n",
      "| VRDeck       | float64     |\n",
      "+--------------+-------------+\n",
      "| Name         | object      |\n",
      "+--------------+-------------+\n",
      "| Transported  | bool        |\n",
      "+--------------+-------------+\n"
     ]
    }
   ],
   "source": [
    "#Check for data types\n",
    "print(tabulate(spaceship.dtypes.reset_index().values, headers=['Column', 'Data Type'], tablefmt='grid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check for missing values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------------+\n",
      "| Column       |   Missing Values |\n",
      "+==============+==================+\n",
      "| PassengerId  |                0 |\n",
      "+--------------+------------------+\n",
      "| HomePlanet   |              201 |\n",
      "+--------------+------------------+\n",
      "| CryoSleep    |              217 |\n",
      "+--------------+------------------+\n",
      "| Cabin        |              199 |\n",
      "+--------------+------------------+\n",
      "| Destination  |              182 |\n",
      "+--------------+------------------+\n",
      "| Age          |              179 |\n",
      "+--------------+------------------+\n",
      "| VIP          |              203 |\n",
      "+--------------+------------------+\n",
      "| RoomService  |              181 |\n",
      "+--------------+------------------+\n",
      "| FoodCourt    |              183 |\n",
      "+--------------+------------------+\n",
      "| ShoppingMall |              208 |\n",
      "+--------------+------------------+\n",
      "| Spa          |              183 |\n",
      "+--------------+------------------+\n",
      "| VRDeck       |              188 |\n",
      "+--------------+------------------+\n",
      "| Name         |              200 |\n",
      "+--------------+------------------+\n",
      "| Transported  |                0 |\n",
      "+--------------+------------------+\n"
     ]
    }
   ],
   "source": [
    "#Check for missing values\n",
    "print(tabulate(spaceship.isnull().sum().reset_index().values, headers=['Column', 'Missing Values'], tablefmt='grid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are multiple strategies to handle missing data\n",
    "\n",
    "- Removing all rows or all columns containing missing data.\n",
    "- Filling all missing values with a value (mean in continouos or mode in categorical for example).\n",
    "- Filling all missing values with an algorithm.\n",
    "\n",
    "For this exercise, because we have such low amount of null values, we will drop rows containing any missing value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------------+\n",
      "| Column       |   Missing Values |\n",
      "+==============+==================+\n",
      "| PassengerId  |                0 |\n",
      "+--------------+------------------+\n",
      "| HomePlanet   |                0 |\n",
      "+--------------+------------------+\n",
      "| CryoSleep    |                0 |\n",
      "+--------------+------------------+\n",
      "| Cabin        |                0 |\n",
      "+--------------+------------------+\n",
      "| Destination  |                0 |\n",
      "+--------------+------------------+\n",
      "| Age          |                0 |\n",
      "+--------------+------------------+\n",
      "| VIP          |                0 |\n",
      "+--------------+------------------+\n",
      "| RoomService  |                0 |\n",
      "+--------------+------------------+\n",
      "| FoodCourt    |                0 |\n",
      "+--------------+------------------+\n",
      "| ShoppingMall |                0 |\n",
      "+--------------+------------------+\n",
      "| Spa          |                0 |\n",
      "+--------------+------------------+\n",
      "| VRDeck       |                0 |\n",
      "+--------------+------------------+\n",
      "| Name         |                0 |\n",
      "+--------------+------------------+\n",
      "| Transported  |                0 |\n",
      "+--------------+------------------+\n"
     ]
    }
   ],
   "source": [
    "#Removing all rows or all columns containing missing data.\n",
    "spaceship.dropna(axis=0, how='any', inplace=True)\n",
    "\n",
    "print(tabulate(spaceship.isnull().sum().reset_index().values, headers=['Column', 'Missing Values'], tablefmt='grid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------------+\n",
      "| Column       |   Missing Values |\n",
      "+==============+==================+\n",
      "| PassengerId  |                0 |\n",
      "+--------------+------------------+\n",
      "| HomePlanet   |                0 |\n",
      "+--------------+------------------+\n",
      "| CryoSleep    |                0 |\n",
      "+--------------+------------------+\n",
      "| Cabin        |                0 |\n",
      "+--------------+------------------+\n",
      "| Destination  |                0 |\n",
      "+--------------+------------------+\n",
      "| Age          |                0 |\n",
      "+--------------+------------------+\n",
      "| VIP          |                0 |\n",
      "+--------------+------------------+\n",
      "| RoomService  |                0 |\n",
      "+--------------+------------------+\n",
      "| FoodCourt    |                0 |\n",
      "+--------------+------------------+\n",
      "| ShoppingMall |                0 |\n",
      "+--------------+------------------+\n",
      "| Spa          |                0 |\n",
      "+--------------+------------------+\n",
      "| VRDeck       |                0 |\n",
      "+--------------+------------------+\n",
      "| Name         |                0 |\n",
      "+--------------+------------------+\n",
      "| Transported  |                0 |\n",
      "+--------------+------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cleid\\AppData\\Local\\Temp\\ipykernel_39344\\823681279.py:2: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  spaceship.fillna(method='ffill', inplace=True)\n",
      "C:\\Users\\cleid\\AppData\\Local\\Temp\\ipykernel_39344\\823681279.py:2: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  spaceship.fillna(method='ffill', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "#Filling all missing values with an algorithm\n",
    "spaceship.fillna(method='ffill', inplace=True)\n",
    "print(tabulate(spaceship.isnull().sum().reset_index().values, headers=['Column', 'Missing Values'], tablefmt='grid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**KNN**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K Nearest Neighbors is a distance based algorithm, and requeries all **input data to be numerical.**\n",
    "\n",
    "Let's only select numerical columns as our features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical Columns:\n",
      "+--------------+\n",
      "| Column       |\n",
      "|--------------|\n",
      "| Age          |\n",
      "| RoomService  |\n",
      "| FoodCourt    |\n",
      "| ShoppingMall |\n",
      "| Spa          |\n",
      "| VRDeck       |\n",
      "+--------------+\n",
      "First few rows of the numerical DataFrame:\n",
      "+----+-------+---------------+-------------+----------------+-------+----------+\n",
      "|    |   Age |   RoomService |   FoodCourt |   ShoppingMall |   Spa |   VRDeck |\n",
      "|----+-------+---------------+-------------+----------------+-------+----------|\n",
      "|  0 |    39 |             0 |           0 |              0 |     0 |        0 |\n",
      "|  1 |    24 |           109 |           9 |             25 |   549 |       44 |\n",
      "|  2 |    58 |            43 |        3576 |              0 |  6715 |       49 |\n",
      "|  3 |    33 |             0 |        1283 |            371 |  3329 |      193 |\n",
      "|  4 |    16 |           303 |          70 |            151 |   565 |        2 |\n",
      "+----+-------+---------------+-------------+----------------+-------+----------+\n"
     ]
    }
   ],
   "source": [
    "# Select only numerical columns\n",
    "numerical_columns = spaceship.select_dtypes(include=['number']).columns\n",
    "spaceship_numerical = spaceship[numerical_columns]\n",
    "\n",
    "# Display the numerical columns\n",
    "print(\"Numerical Columns:\")\n",
    "print(tabulate([[col] for col in numerical_columns], headers=['Column'], tablefmt='psql'))\n",
    "\n",
    "# Display the first few rows of the numerical DataFrame\n",
    "print(\"First few rows of the numerical DataFrame:\")\n",
    "print(tabulate(spaceship_numerical.head(), headers='keys', tablefmt='psql'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And also lets define our target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features (X):\n",
      "+---+------+-------------+-----------+--------------+--------+--------+\n",
      "|   | Age  | RoomService | FoodCourt | ShoppingMall |  Spa   | VRDeck |\n",
      "+---+------+-------------+-----------+--------------+--------+--------+\n",
      "| 0 | 39.0 |     0.0     |    0.0    |     0.0      |  0.0   |  0.0   |\n",
      "| 1 | 24.0 |    109.0    |    9.0    |     25.0     | 549.0  |  44.0  |\n",
      "| 2 | 58.0 |    43.0     |  3576.0   |     0.0      | 6715.0 |  49.0  |\n",
      "| 3 | 33.0 |     0.0     |  1283.0   |    371.0     | 3329.0 | 193.0  |\n",
      "| 4 | 16.0 |    303.0    |   70.0    |    151.0     | 565.0  |  2.0   |\n",
      "+---+------+-------------+-----------+--------------+--------+--------+\n",
      "\n",
      "Target (y):\n",
      "+---+-------------+\n",
      "|   | Transported |\n",
      "+---+-------------+\n",
      "| 0 |      0      |\n",
      "| 1 |      1      |\n",
      "| 2 |      0      |\n",
      "| 3 |      0      |\n",
      "| 4 |      1      |\n",
      "+---+-------------+\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = spaceship  # Assign cleaned DataFrame to df\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "X = df.select_dtypes(include=['number'])  # Numerical features\n",
    "y = df['Transported']  # Target variable\n",
    "\n",
    "# Convert the target to numerical data\n",
    "y = y.astype(int)\n",
    "\n",
    "# Display the first few rows of the features (X) using tabulate\n",
    "print(\"Features (X):\")\n",
    "print(tabulate(X.head(), headers='keys', tablefmt='pretty'))\n",
    "\n",
    "# Display the first few values of the target (y) using tabulate\n",
    "print(\"\\nTarget (y):\")\n",
    "print(tabulate(pd.DataFrame(y.head()), headers='keys', tablefmt='pretty'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train Test Split**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have split the data into **features** and **target** variables and imported the **train_test_split** function, split X and y into X_train, X_test, y_train, and y_test. 80% of the data should be in the training set and 20% in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (5284, 6)\n",
      "X_test shape: (1322, 6)\n",
      "y_train shape: (5284,)\n",
      "y_test shape: (1322,)\n",
      "\n",
      "X_train (first 5 rows):\n",
      "+------+------+-------------+-----------+--------------+--------+--------+\n",
      "|      | Age  | RoomService | FoodCourt | ShoppingMall |  Spa   | VRDeck |\n",
      "+------+------+-------------+-----------+--------------+--------+--------+\n",
      "| 7832 | 25.0 |     0.0     |  1673.0   |     0.0      | 642.0  | 612.0  |\n",
      "| 5842 | 36.0 |     0.0     |  2624.0   |    1657.0    | 2799.0 |  1.0   |\n",
      "| 3928 | 34.0 |     0.0     |    0.0    |     0.0      |  0.0   |  0.0   |\n",
      "| 4091 | 37.0 |     0.0     |    0.0    |     0.0      |  0.0   |  0.0   |\n",
      "| 7679 | 22.0 |     0.0     |    0.0    |     0.0      |  0.0   |  0.0   |\n",
      "+------+------+-------------+-----------+--------------+--------+--------+\n",
      "\n",
      "y_train (first 5 values):\n",
      "+------+-------------+\n",
      "|      | Transported |\n",
      "+------+-------------+\n",
      "| 7832 |      0      |\n",
      "| 5842 |      0      |\n",
      "| 3928 |      1      |\n",
      "| 4091 |      1      |\n",
      "| 7679 |      1      |\n",
      "+------+-------------+\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the shapes of the resulting sets\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "\n",
    "# Optional: Display a few rows of the training sets using tabulate\n",
    "print(\"\\nX_train (first 5 rows):\")\n",
    "print(tabulate(X_train.head(), headers='keys', tablefmt='pretty'))\n",
    "print(\"\\ny_train (first 5 values):\")\n",
    "print(tabulate(pd.DataFrame(y_train.head()), headers='keys', tablefmt='pretty'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Selection**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we will be using **KNN** as our predictive model.\n",
    "\n",
    "You need to choose between **Classificator** or **Regressor**. Take into consideration target variable to decide."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize a KNN instance without setting any hyperparameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier()\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Initialize the KNN Classifier\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Display the initialized model (optional)\n",
    "print(knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model to your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN model fitted to the training data.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize the KNN Classifier\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Fit the model to the scaled training data\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"KNN model fitted to the training data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "Accuracy: 0.7693\n",
      "Precision: 0.7622\n",
      "Recall: 0.7907\n",
      "F1-score: 0.7762\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Assuming knn, X_test_scaled, and y_test are already defined\n",
    "\n",
    "# Make predictions on the scaled test data\n",
    "y_pred = knn.predict(X_test_scaled)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Evaluation Metrics:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Congratulations, you have just developed your first Machine Learning model!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
